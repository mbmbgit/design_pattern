スクレイピング・ブラウザ自動化ツール完全網羅リストWebスクレイピングや自動化に使われる主要なライブラリ・ツールをカテゴリ別にまとめました。プロジェクトの要件（JavaScriptが必要か、速度重視か、回避が必要か）に合わせて最適なものを選んでください。1. ブラウザ自動化ツール (動的サイト・SPA向け)JavaScriptで生成されるコンテンツ（React, Vueなど）や、ログイン操作が必要なサイト向けです。ツール名開発元言語特徴・メリットデメリットSelenium 4コミュニティPython, Java, JS, C#等【定番】 最も歴史があり、情報やドキュメントが豊富。あらゆるブラウザに対応。Ver4からCDP(Chrome DevTools Protocol)対応で機能強化。動作が比較的遅い。環境構築（Driver管理）が少し手間。PlaywrightMicrosoftPython, Node.js, .NET, Java【現在の一押し】 高速で安定。ブラウザの自動ダウンロード、強力な自動待機（Auto-wait）、並列実行が得意。歴史が浅いため、Seleniumほど枯れていない（が、急速に主流化）。PuppeteerGoogleNode.js (Python版はPyppeteer)【Chrome特化】 Chrome/Chromiumの制御に特化しており、安定性が高い。Google純正。基本的にChrome系のみ。Pythonで使う場合は非公式ポートが必要で少し使いにくい。どれを選ぶべき？Pythonでモダンに書きたい・速さが欲しい 👉 Playwright情報量重視・古い資産がある 👉 SeleniumNode.js環境・Chromeのみで良い 👉 Puppeteer2. HTTPリクエスト・解析ツール (静的サイト向け)ブラウザを起動せず、サーバーと直接通信します。非常に高速ですが、JavaScriptは動作しません。ツール名役割特徴Requests通信Pythonの標準的なHTTPライブラリ。非常にシンプルで使いやすい。Beautiful Soup 4解析HTML/XMLからデータを抽出するライブラリ。壊れたHTMLにも強い。Requestsとセットで使うのが基本。lxml解析Beautiful Soupより高速な解析ライブラリ。XPathが使えるのが強み。3. 大規模フレームワーク (クローラー向け)ツール名特徴Scrapy【最強のクローラー】 Python製のスクレイピングフレームワーク。非同期処理により爆速で数万ページのデータを収集できる。RequestsやBeautifulSoupとはレベルが違う速度。学習コストは高い。4. 拡張・特殊用途ツール (回避・デバッグ用)ツール名ベース用途・特徴Selenium-WireSelenium【通信のぞき見】 Seleniumに「プロキシ機能」を追加し、裏側のHTTPリクエスト/レスポンス（APIのJSONなど）を傍受・変更できる。undetected-chromedriverSelenium【Bot検知回避】 CloudflareなどのBot対策を突破するために、Selenium特有の痕跡（指紋）を消した改造ドライバー。SeleniumBaseSeleniumSeleniumをラップして使いやすくし、さらにBot検知回避機能も統合した高機能フレームワーク。MechanicalSoupRequestsブラウザを使わずに、RequestsとBeautifulSoupで「ブラウザのような挙動（フォーム入力やボタン操作）」を模倣するライブラリ。軽量。5. 比較まとめ：あなたにおすすめなのは？「とりあえず簡単なデータをサクッと取りたい」👉 Requests + Beautiful Soup (静的サイトならこれが最速・最軽量)「ボタンを押したり、ログインしたり、JSで動くサイトを見たい」👉 Playwright (今から覚えるならこれ)👉 Selenium (日本語情報が多い方がいいならこれ)「裏で流れているAPIのJSONデータを直接引っこ抜きたい」👉 Selenium-Wire (またはPlaywrightのpage.on("response")機能)「数万件の商品データを毎日定期的に集めたい」👉 Scrapy (速度と管理機能が必要になるため)「アクセスしたら『ロボットですか？』と怒られる」👉 undetected-chromedriver または SeleniumBase
